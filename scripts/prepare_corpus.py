"""
–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —á–∏—Å—Ç–æ–≥–æ –∫–æ—Ä–ø—É—Å–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è RADON
"""

import os
import re
import json
from pathlib import Path
from typing import List, Dict, Any
import argparse


def clean_text(text: str) -> str:
    """–û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –æ—Ç –º—É—Å–æ—Ä–∞"""
    
    # –£–¥–∞–ª–µ–Ω–∏–µ HTML —Ç–µ–≥–æ–≤
    text = re.sub(r'<[^>]+>', '', text)
    
    # –£–¥–∞–ª–µ–Ω–∏–µ URL
    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)
    
    # –£–¥–∞–ª–µ–Ω–∏–µ email
    text = re.sub(r'\S+@\S+', '', text)
    
    # –£–¥–∞–ª–µ–Ω–∏–µ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤ –∏ –ø–µ—Ä–µ–Ω–æ—Å–æ–≤
    text = re.sub(r'\s+', ' ', text)
    text = re.sub(r'\n+', '\n', text)
    
    # –£–¥–∞–ª–µ–Ω–∏–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ (–æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –±—É–∫–≤—ã, —Ü–∏—Ñ—Ä—ã, –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é)
    text = re.sub(r'[^\w\s\.\,\!\?\;\:\-\(\)\"\']', '', text)
    
    return text.strip()


def prepare_russian_corpus(
    input_dir: str,
    output_file: str,
    min_length: int = 50,
    max_length: int = 2000
) -> Dict[str, Any]:
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ä—É—Å—Å–∫–æ–≥–æ –∫–æ—Ä–ø—É—Å–∞"""
    
    print("[+] Preparing Russian corpus...")
    
    russian_texts = []
    total_chars = 0
    
    # –ü–æ–∏—Å–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤
    for file_path in Path(input_dir).rglob("*.txt"):
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
            cleaned = clean_text(content)
            
            # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –¥–ª–∏–Ω–µ
            if min_length <= len(cleaned) <= max_length:
                russian_texts.append(cleaned)
                total_chars += len(cleaned)
                
        except Exception as e:
            print(f"‚ö†Ô∏è  Error processing {file_path}: {e}")
            continue
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ—Ä–ø—É—Å–∞
    with open(output_file, 'w', encoding='utf-8') as f:
        for text in russian_texts:
            f.write(text + '\n\n')
    
    stats = {
        "total_texts": len(russian_texts),
        "total_chars": total_chars,
        "avg_length": total_chars // len(russian_texts) if russian_texts else 0
    }
    
    print(f"‚úÖ Russian corpus: {stats['total_texts']} texts, {stats['total_chars']:,} chars")
    return stats


def prepare_english_corpus(
    input_dir: str,
    output_file: str,
    min_length: int = 50,
    max_length: int = 2000
) -> Dict[str, Any]:
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ –∫–æ—Ä–ø—É—Å–∞"""
    
    print("[+] Preparing English corpus...")
    
    english_texts = []
    total_chars = 0
    
    # –ü–æ–∏—Å–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤
    for file_path in Path(input_dir).rglob("*.txt"):
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
            cleaned = clean_text(content)
            
            # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –¥–ª–∏–Ω–µ
            if min_length <= len(cleaned) <= max_length:
                english_texts.append(cleaned)
                total_chars += len(cleaned)
                
        except Exception as e:
            print(f"‚ö†Ô∏è  Error processing {file_path}: {e}")
            continue
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ—Ä–ø—É—Å–∞
    with open(output_file, 'w', encoding='utf-8') as f:
        for text in english_texts:
            f.write(text + '\n\n')
    
    stats = {
        "total_texts": len(english_texts),
        "total_chars": total_chars,
        "avg_length": total_chars // len(english_texts) if english_texts else 0
    }
    
    print(f"‚úÖ English corpus: {stats['total_texts']} texts, {stats['total_chars']:,} chars")
    return stats


def prepare_code_corpus(
    input_dir: str,
    output_file: str,
    min_length: int = 20,
    max_length: int = 1000
) -> Dict[str, Any]:
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ—Ä–ø—É—Å–∞ –∫–æ–¥–∞"""
    
    print("[+] Preparing code corpus...")
    
    code_extensions = ['.py', '.js', '.ts', '.java', '.cpp', '.c', '.h', '.go', '.rs']
    code_texts = []
    total_chars = 0
    
    # –ü–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤ –∫–æ–¥–∞
    for ext in code_extensions:
        for file_path in Path(input_dir).rglob(f"*{ext}"):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # –û—á–∏—Å—Ç–∫–∞ –∫–æ–¥–∞ (—É–¥–∞–ª–µ–Ω–∏–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤, –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤)
                cleaned = clean_text(content)
                
                # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –¥–ª–∏–Ω–µ
                if min_length <= len(cleaned) <= max_length:
                    code_texts.append(cleaned)
                    total_chars += len(cleaned)
                    
            except Exception as e:
                print(f"‚ö†Ô∏è  Error processing {file_path}: {e}")
                continue
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ—Ä–ø—É—Å–∞
    with open(output_file, 'w', encoding='utf-8') as f:
        for text in code_texts:
            f.write(text + '\n\n')
    
    stats = {
        "total_texts": len(code_texts),
        "total_chars": total_chars,
        "avg_length": total_chars // len(code_texts) if code_texts else 0
    }
    
    print(f"‚úÖ Code corpus: {stats['total_texts']} texts, {stats['total_chars']:,} chars")
    return stats


def create_combined_corpus(
    russian_file: str,
    english_file: str,
    code_file: str,
    output_file: str,
    russian_ratio: float = 0.4,
    english_ratio: float = 0.4,
    code_ratio: float = 0.2
) -> Dict[str, Any]:
    """–°–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ –∫–æ—Ä–ø—É—Å–∞"""
    
    print("[+] Creating combined corpus...")
    
    # –ß—Ç–µ–Ω–∏–µ –∫–æ—Ä–ø—É—Å–æ–≤
    with open(russian_file, 'r', encoding='utf-8') as f:
        russian_texts = [line.strip() for line in f if line.strip()]
    
    with open(english_file, 'r', encoding='utf-8') as f:
        english_texts = [line.strip() for line in f if line.strip()]
    
    with open(code_file, 'r', encoding='utf-8') as f:
        code_texts = [line.strip() for line in f if line.strip()]
    
    # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —è–∑—ã–∫–∞
    total_texts = len(russian_texts) + len(english_texts) + len(code_texts)
    russian_count = int(total_texts * russian_ratio)
    english_count = int(total_texts * english_ratio)
    code_count = int(total_texts * code_ratio)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ –∫–æ—Ä–ø—É—Å–∞
    combined_texts = []
    
    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ä—É—Å—Å–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤
    combined_texts.extend(russian_texts[:russian_count])
    
    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∞–Ω–≥–ª–∏–π—Å–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤
    combined_texts.extend(english_texts[:english_count])
    
    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–æ–¥–∞
    combined_texts.extend(code_texts[:code_count])
    
    # –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–Ω–∏–µ
    import random
    random.shuffle(combined_texts)
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    with open(output_file, 'w', encoding='utf-8') as f:
        for text in combined_texts:
            f.write(text + '\n\n')
    
    stats = {
        "total_texts": len(combined_texts),
        "russian_texts": russian_count,
        "english_texts": english_count,
        "code_texts": code_count,
        "total_chars": sum(len(text) for text in combined_texts)
    }
    
    print(f"‚úÖ Combined corpus: {stats['total_texts']} texts, {stats['total_chars']:,} chars")
    return stats


def main():
    parser = argparse.ArgumentParser(description="Prepare clean corpus for RADON")
    parser.add_argument("--input_dir", required=True, help="Input directory with texts")
    parser.add_argument("--output_dir", default="./data", help="Output directory")
    parser.add_argument("--russian_ratio", type=float, default=0.4, help="Russian text ratio")
    parser.add_argument("--english_ratio", type=float, default=0.4, help="English text ratio")
    parser.add_argument("--code_ratio", type=float, default=0.2, help="Code text ratio")
    
    args = parser.parse_args()
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –≤—ã—Ö–æ–¥–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    os.makedirs(args.output_dir, exist_ok=True)
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ—Ä–ø—É—Å–æ–≤
    russian_stats = prepare_russian_corpus(
        args.input_dir,
        os.path.join(args.output_dir, "russian_corpus.txt")
    )
    
    english_stats = prepare_english_corpus(
        args.input_dir,
        os.path.join(args.output_dir, "english_corpus.txt")
    )
    
    code_stats = prepare_code_corpus(
        args.input_dir,
        os.path.join(args.output_dir, "code_corpus.txt")
    )
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ –∫–æ—Ä–ø—É—Å–∞
    combined_stats = create_combined_corpus(
        os.path.join(args.output_dir, "russian_corpus.txt"),
        os.path.join(args.output_dir, "english_corpus.txt"),
        os.path.join(args.output_dir, "code_corpus.txt"),
        os.path.join(args.output_dir, "combined_corpus.txt"),
        args.russian_ratio,
        args.english_ratio,
        args.code_ratio
    )
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    stats = {
        "russian": russian_stats,
        "english": english_stats,
        "code": code_stats,
        "combined": combined_stats
    }
    
    with open(os.path.join(args.output_dir, "corpus_stats.json"), 'w', encoding='utf-8') as f:
        json.dump(stats, f, indent=2, ensure_ascii=False)
    
    print("\nüéâ Corpus preparation complete!")
    print(f"üìä Statistics saved to {args.output_dir}/corpus_stats.json")


if __name__ == "__main__":
    main()
